---
layout: post
title: "Sharing a filesystem between multiple Kubernetes workers"
subtitle: "Using EFS"
date: 2020-04-12 00:30:00 -0400
background: '/img/posts/02.jpg'
---

## Timeout errors and asynchronous jobs
If a client sends a request to a server, and doesn't receive a response for a long time, it will typically throw a timeout error. This marks the request as failed, and is done to stop users from waiting indefinitely. These timeout errors can happen for a variety of reasons, such as network infrastructure errors or bad error handling on the server side. Sometimes, this error is thrown when a perfectly valid request simply takes too long to process server-side.

To cut down on timeout errors, compute-intensive tasks can be handled asynchronously. I've seen this implemented in two ways, and in both cases, it starts with a synchronous response to the request, effectively saying "We've received your request, it's valid, and are dealing with it".


#### Polling
The last time I saw asynchronous PDF generation, the requester would then poll the server every second, asking if the PDF is ready yet. The server would give 2xx responses which would say "No, it's not ready but keep asking me", until the PDF was generated. The next polling request would receive the PDF as a response.


#### Websockets
The solution that's being implemented now uses websockets. These open up a connection between the client and the server, allowing the server to send messages without receiving a request first. When the PDF is generated, the server sends a websocket "PDF is ready" message to the client. The client then sends an HTTPS request requesting the PDF, and the server responds synchronously.


#### Polling vs Websockets
Polling increases the total amount of network traffic, but the implementation I saw was used between two microservices running in the same Kubernetes cluster. Websockets require an open connection between clients and servers, and I don't know whether this scales very well. Maybe it'll be worth another post in the future.


## Our problem
To avoid timeout errors in Passenger Assist, Transreport have made our PDF reports asynchronous. This works great in local development, where one machine runs both Rails and Sidekiq. This is because the Rails application has access to the PDF generated by Sidekiq. However, in Kubernetes, Rails is run on different pods to Sidekiq, preventing the API from accessing the generated PDF.

To solve this issue, a developer suggested writing PDFs to S3 in Sidekiq, and reading them from Rails. However, this would increase latency by sending requests all the way to the S3 API. Given the fact that Rails and Sidekiq are both running on the same Kubernetes cluster, this seems like a wasted opportunity. Therefore, I suggested mounting a volume into the worker nodes, to share the PDF between the processes locally. To solve this, I initially suggested that we could simply mount a directory from each EC2 instance straight into all Sidekiq and Rails pods running on it, but because the pods are spread across multiple workers, this would fail in cases where the cooperating Rails and Sidekiq pods weren't running on the same machine. Therefore, I decided to use AWS EFS, a shared filesystem that can be mounted into all of our worker nodes, and then into all of our Sidekiq and Rails pods.

#### Implementation

I decided to create everything manually at first, and then import it into Terraform afterwards. An [AWS blog post](https://aws.amazon.com/premiumsupport/knowledge-center/eks-pods-efs/) that I found explains the recommended architecture used for adding an EFS volume to your Kubernetes cluster.

TO BE CONTINUED